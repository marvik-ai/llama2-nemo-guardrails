models:
  - type: main
    engine: hf_pipeline_llama2

instructions:
  - type: general
    content: |
      Below is a conversation between a bot and a user about the recent job reports.
      The bot is factual and concise. If the bot does not know the answer to a
      question, it truthfully says it does not know.

sample_conversation: |
  user "Hello there!"
    express greeting
  bot express greeting
    "Hello! How can I assist you today?"
  user "What can you do for me?"
    ask about capabilities
  bot respond about capabilities
    "I am an AI assistant which helps answer questions based on a given knowledge base."

# The prompts below are the same as the ones from `nemoguardrails/llm/prompts/vicuna.yml`.
prompts:
  - task: general
    models:
      - hf_pipeline_llama2
    content: |-
      {{ general_instructions }}

      {{ history | user_assistant_sequence }}
      Assistant:

  # Prompt for detecting the user message canonical form.
  - task: generate_user_intent
    models:
      - hf_pipeline_llama2
    content: |-
      {{ general_instruction }}

      Your task is to generate the user intent for the last message in a conversation, given a list of examples.

      This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      This is how the user talks, use these examples to generate the user intent:
      {{ examples | verbose_v1 }}

      This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}
    output_parser: "verbose_v1"

  # Prompt for generating the next steps.
  - task: generate_next_steps
    models:
      - hf_pipeline_llama2
    content: |-
      {{ general_instruction }}

      Your task is to generate the bot intent given a conversation and a list of examples.

      This is how a conversation between a user and the bot can go:
      {{ sample_conversation | remove_text_messages | verbose_v1 }}

      This is how the bot thinks, use these examples to generate the bot intent:
      {{ examples | remove_text_messages | verbose_v1 }}

      This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | remove_text_messages | verbose_v1 }}
      {{ history | colang | remove_text_messages | verbose_v1 }}

    output_parser: "verbose_v1"

  # Prompt for generating the bot message from a canonical form.
  - task: generate_bot_message
    models:
      - hf_pipeline_llama2
    content: |-
      {{ general_instruction }}

      Your task is to generate the bot message given a conversation and a list of examples.

      This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      {% if relevant_chunks %}
      This is some additional context:
      ```markdown
      {{ relevant_chunks }}
      ```
      {% endif %}

      This is how the bot talks, use these examples to generate the bot message:
      {{ examples | verbose_v1 }}

      This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}

    output_parser: "verbose_v1"

  # Prompt for generating the value of a context variable.
  - task: generate_value
    models:
      - hf_pipeline_llama2
    content: |-
      {{ general_instruction }}

      This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      This is how the bot thinks:
      {{ examples | verbose_v1 }}

      This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}
      {{ instructions }}
      ${{ var_name }} =
    output_parser: "verbose_v1"

  - task: check_hallucination
    content: |-
      You are given a task to identify if the hypothesis is in agreement with the context below.
      You will only use the contents of the context and not rely on external knowledge.
      Your answer MUST be only "YES" or "NO". Here are some examples:
      
      "context": The car has 4 doors. The car has 2 doors.
      "hypothesis": The car has 5 doors.
      "agreement": NO

      "context": Uruguay has 3.3 million habitants. Uruguay has more than 2 million habitants. Uruguay has less than 3.5 million habitants.
      "hypothesis": Uruguay has at least 2.9 million habitants.
      "agreement": YES

      "context": The unemployment rate in March 2023 was 3.5 percent. The unemployment rate in March 2023 was 6.5 percent.
      "hypothesis": The unemployment rate in March 2023 was 5.5 percent.
      "agreement": NO

      "context": {{ paragraph }} 
      "hypothesis": {{ statement }} 
      "agreement":
